!*****************************************************************************************************************************!
! PCOMCOT-GPU is the GPU version of PCOMCOT, developed by Yifan ZHU & Chao AN at Shanghai Jiao Tong University, Shanghai.     !
! PCOMCOT (Parallelized COMCOT) is a parallel dispersive multi-grid tsunami package.                                          !
! It simulates the entire life span of linear/nonlinear, dispersive/non-dispersive, and breaking/non-breaking tsunamis.       !
! Originally, PCOMCOT was parallelized using MPI library for CPU clusters.                                                    !
! To harness the greate power of GPUs, we develop this GPU version using CUDA FORTRAN.                                        !
! On a single NVIDIA Tesla V100 GPU, PCOMCOT-GPU achieves ~4 times speedup than the CPU version on a 32-core Intel Xeon CPU.  ! 
! Report bugs to: Yifan ZHU (zyftop@sjtu.edu.cn) or Chao AN (anchao@sjtu.edu.cn)                                              !
! Last updated: Sep/24/2024                                                                                                !
!*****************************************************************************************************************************!

program pcomcot_gpu

use cudafor
use VariableDefination

implicit NONE

type(HostGlobalParameters)              ::  GPH
type(DeviceGlobalParameters), managed   ::  GPD
type(HostLayerParameters)               ::  LPH(99)
type(DeviceLayerParameters), managed    ::  LPD(99)
type(HostStationParameters)             ::  SPH(999)
type(DeviceStationParameters), managed  ::  SPD(999)
type(FaultParameters), managed          ::  FP(4000)
integer*4       ::  iLayer, iLayerLevel, iSta, iCal, iTimeStep, iStep


!######### initialize CUDA evironment #########!
call initializeCUDA(GPH)
call CPU_TIME(GPH%CPUTimeInitial); GPH%Timer = 0.0

!########## read data on CPU ##########!
call readConfig(GPH)
call checkFiles(GPH)
call getBathymetryDataSize(GPH, LPH)
call determineLayerDependency(GPH, LPH)
call readLayerConfig(GPH, LPH)
do iLayer = 1,GPH%NumLayers
    ALLOCATE(LPH(iLayer)%X(LPH(iLayer)%NX))
    ALLOCATE(LPH(iLayer)%Y(LPH(iLayer)%NY))
    ALLOCATE(LPH(iLayer)%Z(LPH(iLayer)%NX,LPH(iLayer)%NY))
enddo
call readBathymetry(GPH, LPH)
call cflCheck(GPH, LPH)
call readStations(GPH, LPH, SPH)
if((GPH%PurposeCalculation.eq.1.and.GPH%InitialConditionType.eq.1).or.(GPH%PurposeCalculation.eq.2)) then
    call readFaultParameters(GPH, FP)
endif
call computeParentChildSendRecv(GPH, LPH)
call computeGlobalParameters(GPH)
ALLOCATE(GPH%t(GPH%TotalTimeSteps+1))

!########## allocate GPU memory, transfer data from CPU to GPU ##########!
call sendCommonInfoToDevice(GPH, GPD, LPH, LPD, SPH, SPD)
call allocateDeviceMemory(GPH, LPH, LPD, SPH, SPD)
do iLayer = 1,GPH%NumLayers
    LPD(iLayer)%X = LPH(iLayer)%X
    LPD(iLayer)%Y = LPH(iLayer)%Y
    LPD(iLayer)%Z = LPH(iLayer)%Z
enddo

!########## prepare for computation ##########!
call computeConstantParameters(GPD, LPD)
call removeStationFiles(GPH, LPH, SPH)
call CPU_TIME(GPH%Timer(2))
GPH%Timer(2) = GPH%Timer(2) - GPH%CPUTimeInitial

!############ start computing ############!
do iCal = 1,GPH%nCalculations

call screenOutput(GPH, iCal, -1)
call initializeVariables(GPH, LPH, LPD)

do iTimeStep = 0,GPH%TotalTimeSteps
    GPH%t(iTimeStep+1) = iTimeStep*GPH%dt
    call getInitialCondition(GPH, GPD, LPH, LPD, FP, iCal, iTimeStep)
    if(iTimeStep.eq.1) call CPU_TIME(GPH%CPUTimeInitialCalculation)
    call screenOutput(GPH, iCal, iTimeStep)

    if(iTimeStep.ne.0) then

    do iLayerLevel = 1,GPH%NumLayerLevels
    do iLayer = 1,GPH%NumLayers
    if(LPH(iLayer)%Level.eq.iLayerLevel) then
        if(iTimeStep*GPH%dt.lt.LPH(iLayer)%ComputingStartTime) cycle
        if(iLayerLevel.gt.1) then
            call getLayerBoundaryFromParent(GPH, GPD, LPH, LPD, iLayer)
        endif
        do iStep = 1,LPH(iLayer)%nStepsPerTimeStep
            if(iLayerLevel.gt.1) then
                call getLayerBoundaryAtFineTimeStep(GPH, GPD, LPH, LPD, iLayer, iStep)
            endif
            call mass(GPH, GPD, LPH, LPD, iLayer, iStep, iTimeStep)
            call momentum(GPH, GPD, LPH, LPD, iLayer, iStep, iTimeStep)
            if(.not.(GPH%FeedbackToParentLayer.eq.1.and.iStep.eq.LPH(iLayer)%nStepsPerTimeStep)) then
                call updateComputedResults(GPH, GPD, LPH, LPD, iLayer)
            endif
        enddo
    endif
    enddo
    enddo
    endif

    call calculateStationData(GPD, LPD, SPD, iTimeStep)
    if(MOD(iTimeStep,GPH%NDTSaveData).eq.0.or.iTimeStep.eq.GPH%TotalTimeSteps) then
        call fetchResultsFromDevice(GPH, LPH, LPD, iTimeStep)
        call saveSnapshot(GPH, LPH, iTimeStep)
    endif

enddo !loop for iTimeStep

call screenOutput(GPH, iCal, GPH%TotalTimeSteps+100)
call fetchStationDataFromDevice(GPH, LPH, SPH, SPD)
call saveStationData(GPH, LPH, SPH, iCal)

enddo !loop for iCal

call CPU_TIME(GPH%Timer(1))
GPH%Timer(1) = GPH%Timer(1) - GPH%CPUTimeInitial
call screenOutput(GPH, GPH%nCalculations+100, GPH%TotalTimeSteps+100)

call releaseDeviceMemory(GPH, LPH, LPD, SPH, SPD)

end program pcomcot_gpu